{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\61098577\\Downloads\\ML\\label\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The require model used \n",
    "load_model = \"microsoft/DialoGPT-medium\"\n",
    "\n",
    "# download and cache tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(load_model)\n",
    "\n",
    "# download and cache pre-trained model\n",
    "model = AutoModelForCausalLM.from_pretrained(load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file containing question-answer pairs with intents\n",
    "def load_json_data(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Build a ChatBot class with all necessary modules to make a complete conversation\n",
    "class ChatBot():\n",
    "\n",
    "    def __init__(self, json_filepath=None):\n",
    "\n",
    "        # Initialize chatbot history\n",
    "        self.chat_history_ids = None\n",
    "        self.end_chat = False\n",
    "        \n",
    "        # Load the JSON file for Q&A if provided\n",
    "        self.qa_data = None\n",
    "        if json_filepath:\n",
    "            self.qa_data = load_json_data(json_filepath)\n",
    "        \n",
    "        # Greet when starting\n",
    "        self.welcome()\n",
    "        \n",
    "    def welcome(self):\n",
    "\n",
    "        print(\" Welcome to Inquiry Area.......\")\n",
    "        time.sleep(2)\n",
    "        print('Type \"Namaskar\" or \"quit\" or \"exit\" or \"Adios\" or \"Auf Wiedersehen\" to end chat \\n')\n",
    "        time.sleep(3)\n",
    "        greeting = np.random.choice([\n",
    "            \"Welcome! I'm your chatbot companion. How can I assist you?\",\n",
    "            \"Good to see you! I'm your virtual helper, always ready to serve.\",\n",
    "            \"Hello! It's great to connect with you. What can I do for you?\",\n",
    "            \"Hi! I'm here to provide you with the best assistance possible.\",\n",
    "            \"Hi, I am a ChatBot. Let's chat!\",\n",
    "            \"Hey! I'm your virtual assistant. Let's get started!\"\n",
    "        ])\n",
    "        print(\"ChatBot >> \" + greeting)\n",
    "        \n",
    "    def user_input(self):\n",
    "\n",
    "        # Receive input from user\n",
    "        text = input(\"User >> \")\n",
    "        if text.lower().strip() in ['bye', 'quit', 'exit','Adios','Auf Wiedersehen','Namaskar']:\n",
    "            self.end_chat = True\n",
    "            print('ChatBot ----->> See you soon! Bye!')\n",
    "            time.sleep(1)\n",
    "            print('\\n Quitting ChatBot ...')\n",
    "            return None  # End the loop if chat ends\n",
    "        else:\n",
    "            # Preprocess the input text\n",
    "            self.new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token, return_tensors='pt')\n",
    "            return text\n",
    "\n",
    "    def fetch_answer_from_intent(self, query):\n",
    "        if self.qa_data:\n",
    "            for intent_data in self.qa_data:\n",
    "                intent = intent_data.get('intent', '')\n",
    "                examples = intent_data.get('examples', [])\n",
    "                response = intent_data.get('response', \"Sorry, I don't have an answer to that.\")\n",
    "                \n",
    "                # Checking the query if it matches any of the json intent using regex for case-insensitive matching\n",
    "                for example in examples:\n",
    "                    if re.search(re.escape(example.lower()), query.lower()):\n",
    "                        return response\n",
    "        return None\n",
    "\n",
    "    def bot_response(self, user_query):\n",
    "        # Try to find a response based on the user's query from JSON intent data\n",
    "        response = self.fetch_answer_from_intent(user_query)\n",
    "        \n",
    "        if response:\n",
    "            print(\"ChatBot >> \" + response)\n",
    "        else:\n",
    "            # No match found in JSON, generate a response from the model\n",
    "            if self.chat_history_ids is not None:\n",
    "                self.bot_input_ids = torch.cat([self.chat_history_ids, self.new_user_input_ids], dim=-1)\n",
    "            else:\n",
    "                self.bot_input_ids = self.new_user_input_ids\n",
    "\n",
    "            # Generating a response from the model as loaded from huggingface\n",
    "            self.chat_history_ids = model.generate(self.bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id, no_repeat_ngram_size=2)\n",
    "            bot_response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "\n",
    "            if bot_response == \"\":\n",
    "                bot_response = self.random_response()\n",
    "\n",
    "            print('ChatBot >> ' + bot_response)\n",
    "\n",
    "    def random_response(self):\n",
    "        i = -1\n",
    "        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], skip_special_tokens=True)\n",
    "        \n",
    "        while response == '':\n",
    "            i = i - 1\n",
    "            response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], skip_special_tokens=True)\n",
    "        \n",
    "        if response.strip() == '?':\n",
    "            reply = np.random.choice([\"I don't know\", \"I am not sure\"])\n",
    "        else:\n",
    "            reply = np.random.choice([\"Great\", \"Fine. What's up?\", \"Okay\"])\n",
    "        \n",
    "        return reply\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome to Inquiry Area.......\n",
      "Type \"Namaskar\" or \"quit\" or \"exit\" or \"Adios\" or \"Auf Wiedersehen\" to end chat \n",
      "\n",
      "ChatBot >> Good to see you! I'm your virtual helper, always ready to serve.\n",
      "ChatBot >> Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot >> I'm not sure what you're asking.\n",
      "ChatBot >> We offer consulting, software development, and data analysis.\n"
     ]
    }
   ],
   "source": [
    "# Build a ChatBot object with the path to your JSON file\n",
    "json_filepath = './chatbotquery.json'  # Replace with your actual file path\n",
    "bot = ChatBot(json_filepath=json_filepath)\n",
    "\n",
    "# Start chatting\n",
    "while True:\n",
    "    user_query = bot.user_input()\n",
    "    if bot.end_chat:\n",
    "        break\n",
    "    bot.bot_response(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "label",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
